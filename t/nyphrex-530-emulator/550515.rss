<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Nyphrex - 530 Emulator</title>
    <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515</link>
    <description>[size=12pt]Nyphrex - 530 Emulation[/size]

[b]It has not yet been decided if we will open source our code.[/b]

[u]Overview[/u]

Nyphrex is aimed at emulating Runescape revision 530 and will use modern technology and a custom code base to do so. We hope to have a fully modular Runescape emulation platform that will allow us to horizontally scale to our customers needs. To implement this we will be using technology such as Docker, Rancher, and Protobuf to quickly implement various server implementations such as a login, chat, game, and load balance server.

[u]Chat Service[/u]

The Nyphrex chat server will host the ability for users to publish messages on a single world instance. Other services will poll for messages from various targets, some targets being your name, some targets being the entire public chat to swiftly serve you messages sent to you. The chat server supports message compression, no plans yet for encryption, and does not have a public endpoint for developer interfaces besides those that are held by Nyphrex personnel. 

Current specification:

[code]
LOOKUP target id -&gt; ...
SUBSCRIBE target [target...] -&gt; subscription [subscription...]
PUBLISH source data compression target [target...] -&gt; id
POLL subscription start [limit] -&gt; message [message...]
[/code]

[code]
Chat Server A -&gt; 10.8.10.2
	- Message namespace: [0, 5000000]
Chat Server B -&gt; 11.7.6.3
	- Message namespace: [5000000, 10000000]

Server A {
	// On game world start, subscribe to the chat server assigned to the game server. This server will hold
	// all of the game server subscriptions and possibly other subscriptions for other platform interfaces.

	// Subscribe to the public relay
	SUBSCRIBE public -&gt; &quot;abcdefgh&quot;

	// When a player logs in we need to update the subscription to watch for
	// messages sent to the server.
	UPDATE abcdefgh user:nyphrex
}

// Say we have another world instance which has another chat server assigned to the game server. For demostration purposes.
Server B {
	...
	SUBSCRIBE public -&gt; &quot;defghij&quot;

	// A new player logs in.
	UPDATE defghij user:doug
}

Server A {

	// Say a player sent a private message to doug, we publish the message to server.
	// Note: user:nyphrex being the id is reserved under a specific space, preferably under
	// the unsigned base 37 id assigned to a user from their username. Just image an encoded
	// sint64 there. Seriously.
	//
	// Current compression id is reserved for none, just ascii character encoded sequence.
	PUBLISH user:nyphrex &quot;hello how are you&quot; 0 user:doug

	// Server A searches for a relay on the server under the namespace &#39;user:doug&#39; however since
	// one doesnt exist we can just assume we need to forward the message to the other
	// chat servers in the cloud.
	Server B -&gt; PUBLISH user:nyphrex &quot;hello how are you&quot; 0 user:doug
}

Server B {
	// Server B receives the PUBLISH message from server A and since it contains the relay for doug, we can inform the relay a new message
	// was received! :)
}


// Other considerations: Each server has their own space for subscribers, subscribers are not unique in the context of the cloud. Messages
// are seeded from an offset starting at say 0 for Server A and 50000000 for Server B. These servers will contain messages, for A, 0-500000000,
// for B; 5000000-10000000. This assures that message ids dont conflict and when all servers eventually become informed of the message that
// each server has access to read and lookup the message if an agent uses the LOOKUP command for the message.
[/code]

[code]
public static void main(String... args) {
     Service service = ChatService.newReflectiveService(new ChatServer());
     subscribe(service, &quot;#public&quot;, &quot;#private&quot;, &quot;#other&quot;, &quot;#commands&quot;);
     publish(service, 0xDEADBEEF, &quot;Jet fuel can&#39;t melt steel beams&quot;.getBytes(), 0, &quot;#public&quot;, &quot;#private&quot;);
}

    /**
     * [main] INFO io.nyphrex.chat.ChatServer - SUBSCRIBE relays=[#public, #private, #other, #commands]
     Mar 12, 2015 5:44:11 AM [io.nyphrex.chat.temp.Callback]  handleSubscribe
     INFO: CALLBACK -&gt; sid: 2505867834727897330

     [main] INFO io.nyphrex.chat.ChatServer - PUBLISH source=-1, data=..., compression=0, relays=[#public, #private]
     Mar 12, 2015 5:44:12 AM [io.nyphrex.chat.temp.Callback]  handlePublish
     INFO: CALLBACK -&gt; id: 1

     */
[/code]</description>
    
    <lastBuildDate>Sat, 14 Mar 2015 07:38:48 +0000</lastBuildDate>
    <category>Runescape</category>
    <atom:link href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@Nyphrex Nyphrex]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/nyphrex">@Nyphrex</a> wrote:</p>
          <blockquote>
              <p>[quote=“Zymus, post:11, topic:550515”][quote author=Nyphrex link=topic=669425.msg4476692#msg4476692 date=1426314205]</p>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<p>I always love these kinds of threads.</p>
<blockquote>
<p>horizontally scale<br>
customers needs<br>
Nyphrex personnel<br>
Using custom voids</p>
</blockquote>
</blockquote>
</aside>
<p>These are all correct terms though. I just wanted to also specify the tech we were using in case people were wondering, since the platform design is pretty fun.</p>
</blockquote>
</aside>
<p>Sure they are (custom voids notwithstanding). They’re also all meaningless in this context.</p>
<p>Horizontal scalability? Can you even afford one dedicated server, let alone a cluster? Assuming yes, what sort of configuration are you using when scaling out? Some kind of master-slave scheme?</p>
<p><span class="bbcode-b">Providing multiple instances isn’t expensive in this day and age. When launching a new node we will use a premade docker image, managed from Rancher. Scaling out  Yes, game servers will have a master-slave scheme.</span></p>
<p>Are you doing the balancing in software (e.g., HAProxy) or with a hardware load balancer (e.g.: an F5 load balancer)?</p>
<p><span class="bbcode-b">Software. I have to look into specifics on how, and compare solutions.</span></p>
<p>What happens when you need to fail over because a server dies? Do you have some kind of load balancer in front of the horizontally scaling servers that detects the failure and diverts players from the failed server to a working server?</p>
<p><span class="bbcode-b">Yes.</span></p>
<p>Is the failing over from one server to the others an automatic or manual process?</p>
<p><span class="bbcode-b">Automatic.</span></p>
<p>Jagex has historically done a poor job when it comes to failing over. Specifically, people used to get stuck on a server and couldn’t log back in on another server for quite a while. How do you plan to handle this in your horizontally scaled environment?</p>
<p><span class="bbcode-b">Re-election of responsibility. ie: If login server 0 goes down, then login server 1-3 reassign the range of the players they service through an election until the downed node is back up.</span></p>
<p>Honestly, you’ve out a few bits of jargon to lend credibility to your topic. However anyone with two brain cells to rub together can see you’re talking twaddle.</p>
<p><span class="bbcode-b">Okay.</span></p>
</blockquote>
</aside>
</blockquote>
</aside>
<p>Why the fudge would login server’s 1-3 “elect” on which players they service? If you did have multiple servers for login, it would probably be better to have the client connect to the load balancer, rather than a specific instance, then it could go like</p>
<aside class="quote">
<blockquote>

Balancer: Hey, Bob, you there?

Balancer: Alright, fudge you then. Hey Jim, can you take this guy? I can't get a hold of Bob.
Jim: Sure, I can do that.
[i]loginQueue.pop();[/i]

Balancer: Hey Joe, can you take this guy? I can't get a hold of Bob, and Jim is busy
Joe: Sure, I can do that.
[i]loginQueue.pop(); /&gt;
</blockquote>
</aside>
<p>I mean, it’s not rocket science, and it’s certainly not necessary for something of this size. Besides, a login server should be doing just that. Authenticating users. Nothing more. So if they have to “reassign the range of the players they service”, you’re doing something wrong. It should only be focused on each unique connection, authenticating, and then closing the connection. Not keeping it open in case the player gets dc’d and needs to reconnect.</p>
</blockquote>
</aside>
<p><a href="http://en.wikipedia.org/wiki/Partition_%28database%29" class="onebox" target="_blank" rel="nofollow noopener">http://en.wikipedia.org/wiki/Partition_(database)</a></p>
<p>ie: Server 1 ‘services’ players:uid between 0…5000<br>
ie: Server ‘services’ players:uid between 5000-10000</p>
<p>You’re right, it isn’t rocket science. You just missed the mark on understanding.<br>
[/quote]</p>
<p>You will experience 0 difference in performance, honestly. I work for a major ecommerce clothing site that’s been up for nearly 10 years or more. We just added database partitions last year in November. That’s with 10 years worth of clothes that still exist in the database, and an in-house VC database. You would have to experience at least 2500 different logins in any day before the overhead of partitioning the database becomes justified. And that’s assuming your average player size in the DB is less than 100MB.</p>
<p>It might sound like a good idea, but you’ll put more time and effort into trying to get it working the way you want it to, than the benefit you’ll get out of it.[/quote]</p>
<p>I rather implement the infrastructure with the hope it doesn’t have to be redone in the future/use it for other endeavors.</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/12">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/12</link>
        <pubDate>Sat, 14 Mar 2015 07:38:48 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-12</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@zyle1992 Zymus]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/zyle1992">@zyle1992</a> wrote:</p>
          <blockquote>
              <p>[quote=“Nyphrex, post:10, topic:550515”][quote author=Zymus link=topic=669425.msg4476565#msg4476565 date=1426230907]</p>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<p>I always love these kinds of threads.</p>
<blockquote>
<p>horizontally scale<br>
customers needs<br>
Nyphrex personnel<br>
Using custom voids</p>
</blockquote>
</blockquote>
</aside>
<p>These are all correct terms though. I just wanted to also specify the tech we were using in case people were wondering, since the platform design is pretty fun.</p>
</blockquote>
</aside>
<p>Sure they are (custom voids notwithstanding). They’re also all meaningless in this context.</p>
<p>Horizontal scalability? Can you even afford one dedicated server, let alone a cluster? Assuming yes, what sort of configuration are you using when scaling out? Some kind of master-slave scheme?</p>
<p><span class="bbcode-b">Providing multiple instances isn’t expensive in this day and age. When launching a new node we will use a premade docker image, managed from Rancher. Scaling out  Yes, game servers will have a master-slave scheme.</span></p>
<p>Are you doing the balancing in software (e.g., HAProxy) or with a hardware load balancer (e.g.: an F5 load balancer)?</p>
<p><span class="bbcode-b">Software. I have to look into specifics on how, and compare solutions.</span></p>
<p>What happens when you need to fail over because a server dies? Do you have some kind of load balancer in front of the horizontally scaling servers that detects the failure and diverts players from the failed server to a working server?</p>
<p><span class="bbcode-b">Yes.</span></p>
<p>Is the failing over from one server to the others an automatic or manual process?</p>
<p><span class="bbcode-b">Automatic.</span></p>
<p>Jagex has historically done a poor job when it comes to failing over. Specifically, people used to get stuck on a server and couldn’t log back in on another server for quite a while. How do you plan to handle this in your horizontally scaled environment?</p>
<p><span class="bbcode-b">Re-election of responsibility. ie: If login server 0 goes down, then login server 1-3 reassign the range of the players they service through an election until the downed node is back up.</span></p>
<p>Honestly, you’ve out a few bits of jargon to lend credibility to your topic. However anyone with two brain cells to rub together can see you’re talking twaddle.</p>
<p><span class="bbcode-b">Okay.</span></p>
</blockquote>
</aside>
</blockquote>
</aside>
<p>Why the fudge would login server’s 1-3 “elect” on which players they service? If you did have multiple servers for login, it would probably be better to have the client connect to the load balancer, rather than a specific instance, then it could go like</p>
<aside class="quote">
<blockquote>

Balancer: Hey, Bob, you there?

Balancer: Alright, fudge you then. Hey Jim, can you take this guy? I can't get a hold of Bob.
Jim: Sure, I can do that.
[i]loginQueue.pop();[/i]

Balancer: Hey Joe, can you take this guy? I can't get a hold of Bob, and Jim is busy
Joe: Sure, I can do that.
[i]loginQueue.pop(); /&gt;
</blockquote>
</aside>
<p>I mean, it’s not rocket science, and it’s certainly not necessary for something of this size. Besides, a login server should be doing just that. Authenticating users. Nothing more. So if they have to “reassign the range of the players they service”, you’re doing something wrong. It should only be focused on each unique connection, authenticating, and then closing the connection. Not keeping it open in case the player gets dc’d and needs to reconnect.<br>
[/quote]</p>
<p><a href="http://en.wikipedia.org/wiki/Partition_%28database%29" class="onebox" target="_blank">http://en.wikipedia.org/wiki/Partition_(database)</a></p>
<p>ie: Server 1 ‘services’ players:uid between 0…5000<br>
ie: Server ‘services’ players:uid between 5000-10000</p>
<p>You’re right, it isn’t rocket science. You just missed the mark on understanding.[/quote]</p>
<p>You will experience 0 difference in performance, honestly. I work for a major ecommerce clothing site that’s been up for nearly 10 years or more. We just added database partitions last year in November. That’s with 10 years worth of clothes that still exist in the database, and an in-house VC database. You would have to experience at least 2500 different logins in any day before the overhead of partitioning the database becomes justified. And that’s assuming your average player size in the DB is less than 100MB.</p>
<p>It might sound like a good idea, but you’ll put more time and effort into trying to get it working the way you want it to, than the benefit you’ll get out of it.</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/11">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/11</link>
        <pubDate>Sat, 14 Mar 2015 07:27:58 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-11</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@Nyphrex Nyphrex]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/nyphrex">@Nyphrex</a> wrote:</p>
          <blockquote>
              <p>[quote=“Zymus, post:9, topic:550515”][quote author=Nyphrex link=topic=669425.msg4476429#msg4476429 date=1426158652]</p>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<p>I always love these kinds of threads.</p>
<blockquote>
<p>horizontally scale<br>
customers needs<br>
Nyphrex personnel<br>
Using custom voids</p>
</blockquote>
</blockquote>
</aside>
<p>These are all correct terms though. I just wanted to also specify the tech we were using in case people were wondering, since the platform design is pretty fun.</p>
</blockquote>
</aside>
<p>Sure they are (custom voids notwithstanding). They’re also all meaningless in this context.</p>
<p>Horizontal scalability? Can you even afford one dedicated server, let alone a cluster? Assuming yes, what sort of configuration are you using when scaling out? Some kind of master-slave scheme?</p>
<p><span class="bbcode-b">Providing multiple instances isn’t expensive in this day and age. When launching a new node we will use a premade docker image, managed from Rancher. Scaling out  Yes, game servers will have a master-slave scheme.</span></p>
<p>Are you doing the balancing in software (e.g., HAProxy) or with a hardware load balancer (e.g.: an F5 load balancer)?</p>
<p><span class="bbcode-b">Software. I have to look into specifics on how, and compare solutions.</span></p>
<p>What happens when you need to fail over because a server dies? Do you have some kind of load balancer in front of the horizontally scaling servers that detects the failure and diverts players from the failed server to a working server?</p>
<p><span class="bbcode-b">Yes.</span></p>
<p>Is the failing over from one server to the others an automatic or manual process?</p>
<p><span class="bbcode-b">Automatic.</span></p>
<p>Jagex has historically done a poor job when it comes to failing over. Specifically, people used to get stuck on a server and couldn’t log back in on another server for quite a while. How do you plan to handle this in your horizontally scaled environment?</p>
<p><span class="bbcode-b">Re-election of responsibility. ie: If login server 0 goes down, then login server 1-3 reassign the range of the players they service through an election until the downed node is back up.</span></p>
<p>Honestly, you’ve out a few bits of jargon to lend credibility to your topic. However anyone with two brain cells to rub together can see you’re talking twaddle.</p>
<p><span class="bbcode-b">Okay.</span></p>
</blockquote>
</aside>
<p>[/quote]</p>
<p>Why the fudge would login server’s 1-3 “elect” on which players they service? If you did have multiple servers for login, it would probably be better to have the client connect to the load balancer, rather than a specific instance, then it could go like</p>
<aside class="quote">
<blockquote>

Balancer: Hey, Bob, you there?

Balancer: Alright, fudge you then. Hey Jim, can you take this guy? I can't get a hold of Bob.
Jim: Sure, I can do that.
[i]loginQueue.pop();[/i]

Balancer: Hey Joe, can you take this guy? I can't get a hold of Bob, and Jim is busy
Joe: Sure, I can do that.
[i]loginQueue.pop(); /&gt;
</blockquote>
</aside>
<p>I mean, it’s not rocket science, and it’s certainly not necessary for something of this size. Besides, a login server should be doing just that. Authenticating users. Nothing more. So if they have to “reassign the range of the players they service”, you’re doing something wrong. It should only be focused on each unique connection, authenticating, and then closing the connection. Not keeping it open in case the player gets dc’d and needs to reconnect.[/quote]</p>
<p><a href="http://en.wikipedia.org/wiki/Partition_%28database%29" class="onebox" target="_blank" rel="nofollow noopener">http://en.wikipedia.org/wiki/Partition_(database)</a></p>
<p>ie: Server 1 ‘services’ players:uid between 0…5000<br>
ie: Server ‘services’ players:uid between 5000-10000</p>
<p>You’re right, it isn’t rocket science. You just missed the mark on understanding.</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/10">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/10</link>
        <pubDate>Sat, 14 Mar 2015 06:23:25 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-10</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@zyle1992 Zymus]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/zyle1992">@zyle1992</a> wrote:</p>
          <blockquote>
              <p>[quote=“Nyphrex, post:7, topic:550515”][quote author=Lothy link=topic=669425.msg4476427#msg4476427 date=1426157300]</p>
<aside class="quote">
<blockquote>
<aside class="quote">
<blockquote>
<p>I always love these kinds of threads.</p>
<blockquote>
<p>horizontally scale<br>
customers needs<br>
Nyphrex personnel<br>
Using custom voids</p>
</blockquote>
</blockquote>
</aside>
<p>These are all correct terms though. I just wanted to also specify the tech we were using in case people were wondering, since the platform design is pretty fun.</p>
</blockquote>
</aside>
<p>Sure they are (custom voids notwithstanding). They’re also all meaningless in this context.</p>
<p>Horizontal scalability? Can you even afford one dedicated server, let alone a cluster? Assuming yes, what sort of configuration are you using when scaling out? Some kind of master-slave scheme?</p>
<p><span class="bbcode-b">Providing multiple instances isn’t expensive in this day and age. When launching a new node we will use a premade docker image, managed from Rancher. Scaling out  Yes, game servers will have a master-slave scheme.</span></p>
<p>Are you doing the balancing in software (e.g., HAProxy) or with a hardware load balancer (e.g.: an F5 load balancer)?</p>
<p><span class="bbcode-b">Software. I have to look into specifics on how, and compare solutions.</span></p>
<p>What happens when you need to fail over because a server dies? Do you have some kind of load balancer in front of the horizontally scaling servers that detects the failure and diverts players from the failed server to a working server?</p>
<p><span class="bbcode-b">Yes.</span></p>
<p>Is the failing over from one server to the others an automatic or manual process?</p>
<p><span class="bbcode-b">Automatic.</span></p>
<p>Jagex has historically done a poor job when it comes to failing over. Specifically, people used to get stuck on a server and couldn’t log back in on another server for quite a while. How do you plan to handle this in your horizontally scaled environment?</p>
<p><span class="bbcode-b">Re-election of responsibility. ie: If login server 0 goes down, then login server 1-3 reassign the range of the players they service through an election until the downed node is back up.</span></p>
<p>Honestly, you’ve out a few bits of jargon to lend credibility to your topic. However anyone with two brain cells to rub together can see you’re talking twaddle.</p>
<p><span class="bbcode-b">Okay.</span><br>
[/quote][/quote]</p>
<p>Why the fuck would login server’s 1-3 “elect” on which players they service? If you did have multiple servers for login, it would probably be better to have the client connect to the load balancer, rather than a specific instance, then it could go like</p>
<blockquote>
Balancer: Hey, Bob, you there?

Balancer: Alright, fuck you then. Hey Jim, can you take this guy? I can't get a hold of Bob.
Jim: Sure, I can do that.
[i]loginQueue.pop();[/i]

Balancer: Hey Joe, can you take this guy? I can't get a hold of Bob, and Jim is busy
Joe: Sure, I can do that.
[i]loginQueue.pop(); /&gt;</blockquote>
<p>I mean, it’s not rocket science, and it’s certainly not necessary for something of this size. Besides, a login server should be doing just that. Authenticating users. Nothing more. So if they have to “reassign the range of the players they service”, you’re doing something wrong. It should only be focused on each unique connection, authenticating, and then closing the connection. Not keeping it open in case the player gets dc’d and needs to reconnect.</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/9">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/9</link>
        <pubDate>Fri, 13 Mar 2015 07:15:07 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-9</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@Mezzyscape562 Mezzyscape562]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/mezzyscape562">@Mezzyscape562</a> wrote:</p>
          <blockquote>
              <p>It saddens me to see what this community has come to. The fact someone has an idea and every single jackass that has remained here is just constantly nagging and won’t even give a bit of support. So what if it doesn’t work out? He’s trying. For gods, sake, no wonder everyone uses Rune-Server nowadays.</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/8">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/8</link>
        <pubDate>Fri, 13 Mar 2015 01:47:45 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-8</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@Nyphrex Nyphrex]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/nyphrex">@Nyphrex</a> wrote:</p>
          <blockquote>
              <p>[quote=“Lothy, post:6, topic:550515”][quote author=Nyphrex link=topic=669425.msg4476421#msg4476421 date=1426151647]</p>
<aside class="quote">
<blockquote>
<p>I always love these kinds of threads.</p>
<blockquote>
<p>horizontally scale<br>
customers needs<br>
Nyphrex personnel<br>
Using custom voids</p>
</blockquote>
</blockquote>
</aside>
<p>These are all correct terms though. I just wanted to also specify the tech we were using in case people were wondering, since the platform design is pretty fun.<br>
[/quote]<br>
Sure they are (custom voids notwithstanding). They’re also all meaningless in this context.</p>
<p>Horizontal scalability? Can you even afford one dedicated server, let alone a cluster? Assuming yes, what sort of configuration are you using when scaling out? Some kind of master-slave scheme?</p>
<p><span class="bbcode-b">Providing multiple instances isn’t expensive in this day and age. When launching a new node we will use a premade docker image, managed from Rancher. Scaling out  Yes, game servers will have a master-slave scheme.</span></p>
<p>Are you doing the balancing in software (e.g., HAProxy) or with a hardware load balancer (e.g.: an F5 load balancer)?</p>
<p><span class="bbcode-b">Software. I have to look into specifics on how, and compare solutions.</span></p>
<p>What happens when you need to fail over because a server dies? Do you have some kind of load balancer in front of the horizontally scaling servers that detects the failure and diverts players from the failed server to a working server?</p>
<p><span class="bbcode-b">Yes.</span></p>
<p>Is the failing over from one server to the others an automatic or manual process?</p>
<p><span class="bbcode-b">Automatic.</span></p>
<p>Jagex has historically done a poor job when it comes to failing over. Specifically, people used to get stuck on a server and couldn’t log back in on another server for quite a while. How do you plan to handle this in your horizontally scaled environment?</p>
<p><span class="bbcode-b">Re-election of responsibility. ie: If login server 0 goes down, then login server 1-3 reassign the range of the players they service through an election until the downed node is back up.</span></p>
<p>Honestly, you’ve out a few bits of jargon to lend credibility to your topic. However anyone with two brain cells to rub together can see you’re talking twaddle.</p>
<p><span class="bbcode-b">Okay.</span>[/quote]</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/7">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/7</link>
        <pubDate>Thu, 12 Mar 2015 11:10:52 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-7</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@lothy Lothy]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/lothy">@lothy</a> wrote:</p>
          <blockquote>
              <p>[quote=“Nyphrex, post:4, topic:550515”][quote author=Jmood link=topic=669425.msg4476417#msg4476417 date=1426149573]<br>
I always love these kinds of threads.</p>
<blockquote>
<p>horizontally scale<br>
customers needs<br>
Nyphrex personnel<br>
Using custom voids<br>
[/quote]</p>
</blockquote>
<p>These are all correct terms though. I just wanted to also specify the tech we were using in case people were wondering, since the platform design is pretty fun.[/quote]<br>
Sure they are (custom voids notwithstanding). They’re also all meaningless in this context.</p>
<p>Horizontal scalability? Can you even afford one dedicated server, let alone a cluster? Assuming yes, what sort of configuration are you using when scaling out? Some kind of master-slave scheme? Are you doing the balancing in software (e.g., HAProxy) or with a hardware load balancer (e.g.: an F5 load balancer)?</p>
<p>What happens when you need to fail over because a server dies? Do you have some kind of load balancer in front of the horizontally scaling servers that detects the failure and diverts players from the failed server to a working server? Is the failing over from one server to the others an automatic or manual process?<br>
Jagex has historically done a poor job when it comes to failing over. Specifically, people used to get stuck on a server and couldn’t log back in on another server for quite a while. How do you plan to handle this in your horizontally scaled environment?</p>
<p>Honestly, you’ve out a few bits of jargon to lend credibility to your topic. However anyone with two brain cells to rub together can see you’re talking twaddle.</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/6">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/6</link>
        <pubDate>Thu, 12 Mar 2015 10:48:20 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-6</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@sinisoul sini]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/sinisoul">@sinisoul</a> wrote:</p>
          <blockquote>
              <p>You should open source this, because I’d be interested in seeing how you’d design this all…although I lold at ‘personnel’. Gl</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/5">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/5</link>
        <pubDate>Thu, 12 Mar 2015 09:15:22 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-5</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@Nyphrex Nyphrex]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/nyphrex">@Nyphrex</a> wrote:</p>
          <blockquote>
              <p>[quote=“Jmood, post:3, topic:550515”]I always love these kinds of threads.</p>
<blockquote>
<p>horizontally scale<br>
customers needs<br>
Nyphrex personnel<br>
Using custom voids[/quote]</p>
</blockquote>
<p>These are all correct terms though. I just wanted to also specify the tech we were using in case people were wondering, since the platform design is pretty fun. Here’s the protobuf file for your trouble to ‘show off’ the protocol.</p>
<pre><code class="lang-auto">\syntax = "proto3";

package chat.protobuf;

option java_package = "io.nyphrex.chat.protobuf";
option java_outer_classname = "ChatProtocol";
option java_generic_services = true;

service ChatService {
    rpc handleSubscribe(SubscribeRequest) returns (SubscribeResponse);  // Subscribe to a target
    rpc handlePublish(PublishRequest) returns (SimpleResponse);         // Publish a message
    rpc handleLookup(LookupRequest) returns (SimpleResponse);           // Lookup a target
    rpc handlePoll(PollRequest) returns (PollResponse);                 // Poll a target
}

/**
 * ============================================
 *                  Requests
 * ============================================
 */

// LOOKUP target id
message LookupRequest {
    optional string target = 1;     // The lookup target
    optional string id = 2;         // The target id
}

// SUBSCRIBE target [target...]
message SubscribeRequest {
    repeated string targets = 1;     // The targets to subscribe for
}

// PUBLISH source data compression relay [relay...]
message PublishRequest {
    optional int64 source = 1;      // The message source
    optional bytes data = 2;        // The encoded message data
    optional int32 compression = 3; // The compression id
    repeated string targets = 4;    // The publishable targets
}

// POLL subscription start [limit]
message PollRequest {
    optional int64 sid = 1;     // The subscription id
    optional int32 limit = 2;   // The message limit
}


/**
 * ============================================
 *                  Responses
 * ============================================
 */


// Simple response message which indicates if the request was successful.
message SimpleResponse {
    optional bool ok = 1;
}

// Subscriber request response message which passes the subscription id.
message SubscribeResponse {
    optional bool successful = 1;   // Flag for if the request was successful.
    optional int64 sid = 2;         // The subscription id.
}

// Publish request response message which passes the published message id back.
message PublishResponse {
    optional bool successful = 1;   // Flag for if the request was successful
    optional int64 id = 2;          // The published message id
}

// Poll request response message which passes each of the messages back.
message PollResponse {
    repeated ChatMessage messages = 1;
}

/**
 * ============================================
 *                  Models
 * ============================================
 */

// Simple model for messages sent to the server including the data and compression.
message ChatMessage {
    optional int64 id = 1;                  // The message id
    optional int64 source = 2;              // The message source
    optional bytes data = 3;                // The message data
    optional int32 compression = 4;         // The compression id
}

// Model for text compression to assure proper compression lookup
message Compression {
    optional int32 id = 1;          // The compression id
    optional string name = 2;       // The compression name
}</code></pre>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/4">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/4</link>
        <pubDate>Thu, 12 Mar 2015 09:14:07 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-4</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@doom_j doom_j]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/doom_j">@doom_j</a> wrote:</p>
          <blockquote>
              <p>I always love these kinds of threads.</p>
<blockquote>
<p>horizontally scale<br>
customers needs<br>
Nyphrex personnel<br>
Using custom voids</p>
</blockquote>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/3">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/3</link>
        <pubDate>Thu, 12 Mar 2015 08:39:33 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-3</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@lothy Lothy]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/lothy">@lothy</a> wrote:</p>
          <blockquote>
              <p>This is the show off section. ‘We hope to have…’ - come back when you have something to show off.</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/2">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/2</link>
        <pubDate>Thu, 12 Mar 2015 08:20:41 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-2</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
      <item>
        <title>Nyphrex - 530 Emulator</title>
        <dc:creator><![CDATA[@Nyphrex Nyphrex]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/nyphrex">@Nyphrex</a> wrote:</p>
          <blockquote>
              <p>[size=12pt]Nyphrex - 530 Emulation[/size]</p>
<p><span class="bbcode-b">It has not yet been decided if we will open source our code.</span></p>
<p><span class="bbcode-u">Overview</span></p>
<p>Nyphrex is aimed at emulating Runescape revision 530 and will use modern technology and a custom code base to do so. We hope to have a fully modular Runescape emulation platform that will allow us to horizontally scale to our customers needs. To implement this we will be using technology such as Docker, Rancher, and Protobuf to quickly implement various server implementations such as a login, chat, game, and load balance server.</p>
<p><span class="bbcode-u">Chat Service</span></p>
<p>The Nyphrex chat server will host the ability for users to publish messages on a single world instance. Other services will poll for messages from various targets, some targets being your name, some targets being the entire public chat to swiftly serve you messages sent to you. The chat server supports message compression, no plans yet for encryption, and does not have a public endpoint for developer interfaces besides those that are held by Nyphrex personnel.</p>
<p>Current specification:</p>
<pre><code class="lang-auto">LOOKUP target id -&gt; ...
SUBSCRIBE target [target...] -&gt; subscription [subscription...]
PUBLISH source data compression target [target...] -&gt; id
POLL subscription start [limit] -&gt; message [message...]</code></pre>
<pre><code class="lang-auto">Chat Server A -&gt; 10.8.10.2
	- Message namespace: [0, 5000000]
Chat Server B -&gt; 11.7.6.3
	- Message namespace: [5000000, 10000000]

Server A {
	// On game world start, subscribe to the chat server assigned to the game server. This server will hold
	// all of the game server subscriptions and possibly other subscriptions for other platform interfaces.

	// Subscribe to the public relay
	SUBSCRIBE public -&gt; "abcdefgh"

	// When a player logs in we need to update the subscription to watch for
	// messages sent to the server.
	UPDATE abcdefgh user:nyphrex
}

// Say we have another world instance which has another chat server assigned to the game server. For demostration purposes.
Server B {
	...
	SUBSCRIBE public -&gt; "defghij"

	// A new player logs in.
	UPDATE defghij user:doug
}

Server A {

	// Say a player sent a private message to doug, we publish the message to server.
	// Note: user:nyphrex being the id is reserved under a specific space, preferably under
	// the unsigned base 37 id assigned to a user from their username. Just image an encoded
	// sint64 there. Seriously.
	//
	// Current compression id is reserved for none, just ascii character encoded sequence.
	PUBLISH user:nyphrex "hello how are you" 0 user:doug

	// Server A searches for a relay on the server under the namespace 'user:doug' however since
	// one doesnt exist we can just assume we need to forward the message to the other
	// chat servers in the cloud.
	Server B -&gt; PUBLISH user:nyphrex "hello how are you" 0 user:doug
}

Server B {
	// Server B receives the PUBLISH message from server A and since it contains the relay for doug, we can inform the relay a new message
	// was received! :)
}


// Other considerations: Each server has their own space for subscribers, subscribers are not unique in the context of the cloud. Messages
// are seeded from an offset starting at say 0 for Server A and 50000000 for Server B. These servers will contain messages, for A, 0-500000000,
// for B; 5000000-10000000. This assures that message ids dont conflict and when all servers eventually become informed of the message that
// each server has access to read and lookup the message if an agent uses the LOOKUP command for the message.</code></pre>
<pre><code class="lang-auto">public static void main(String... args) {
     Service service = ChatService.newReflectiveService(new ChatServer());
     subscribe(service, "#public", "#private", "#other", "#commands");
     publish(service, 0xDEADBEEF, "Jet fuel can't melt steel beams".getBytes(), 0, "#public", "#private");
}

    /**
     * [main] INFO io.nyphrex.chat.ChatServer - SUBSCRIBE relays=[#public, #private, #other, #commands]
     Mar 12, 2015 5:44:11 AM [io.nyphrex.chat.temp.Callback]  handleSubscribe
     INFO: CALLBACK -&gt; sid: 2505867834727897330

     [main] INFO io.nyphrex.chat.ChatServer - PUBLISH source=-1, data=..., compression=0, relays=[#public, #private]
     Mar 12, 2015 5:44:12 AM [io.nyphrex.chat.temp.Callback]  handlePublish
     INFO: CALLBACK -&gt; id: 1

     */</code></pre>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/1">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515/1</link>
        <pubDate>Thu, 12 Mar 2015 07:25:07 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-550515-1</guid>
        <source url="https://forum.moparisthebest.com/t/nyphrex-530-emulator/550515.rss">Nyphrex - 530 Emulator</source>
      </item>
  </channel>
</rss>
