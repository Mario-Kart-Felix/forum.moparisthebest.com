<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>[Discussion]Loading more new model</title>
    <link>https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165</link>
    <description>So.. From the last time I decided to peak into the 317 client.

Everyone is overwriting models, to add new ones. 

From what I understood, we couldn&#39;t raise the newer model limit.. 

So why? And if not, explain. (This isn&#39;t a help section)</description>
    
    <lastBuildDate>Wed, 27 Oct 2010 01:50:14 +0000</lastBuildDate>
    <category>Runescape</category>
    <atom:link href="https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>[Discussion]Loading more new model</title>
        <dc:creator><![CDATA[@badger41 badger41]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/badger41">@badger41</a> wrote:</p>
          <blockquote>
              <p>[quote=“the elve age, post:3, topic:366165”][quote author=badger41 link=topic=462363.msg3382325#msg3382325 date=1288142745]<br>
yes we could? people have been packing all 474 models to the cache for months now.<br>
[/quote]</p>
<p>What about newer custom models. With 474 models, they just find to load what the models.idx and what ever else, and pack them into the cache.</p>
<p>I’m talking about around 10-15 customly made models. (I mean I guess you could pack them into idx format, and do it the same way.)</p>
<p>But are there any other easier ways?[/quote]</p>
<p>im talking about packing all the models into main_file_cache.idx1… People have been doing it for months just like i said. o.O</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165/4">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165/4</link>
        <pubDate>Wed, 27 Oct 2010 01:50:14 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-366165-4</guid>
        <source url="https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165.rss">[Discussion]Loading more new model</source>
      </item>
      <item>
        <title>[Discussion]Loading more new model</title>
        <dc:creator><![CDATA[@the_elve_age the elve age]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/the_elve_age">@the_elve_age</a> wrote:</p>
          <blockquote>
              <aside class="quote no-group" data-post="2" data-topic="366165">
<div class="title">
<div class="quote-controls"></div>
<img alt width="20" height="20" src="https://forum.moparisthebest.com/letter_avatar/badger41/40/5_1887921562df0dabfae55079ddabeb03.png" class="avatar"> badger41:</div>
<blockquote>
<p>yes we could? people have been packing all 474 models to the cache for months now.</p>
</blockquote>
</aside>
<p>What about newer custom models. With 474 models, they just find to load what the models.idx and what ever else, and pack them into the cache.</p>
<p>I’m talking about around 10-15 customly made models. (I mean I guess you could pack them into idx format, and do it the same way.)</p>
<p>But are there any other easier ways?</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165/3">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165/3</link>
        <pubDate>Wed, 27 Oct 2010 01:28:31 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-366165-3</guid>
        <source url="https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165.rss">[Discussion]Loading more new model</source>
      </item>
      <item>
        <title>[Discussion]Loading more new model</title>
        <dc:creator><![CDATA[@badger41 badger41]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/badger41">@badger41</a> wrote:</p>
          <blockquote>
              <p>yes we could? people have been packing all 474 models to the cache for months now.</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165/2">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165/2</link>
        <pubDate>Wed, 27 Oct 2010 01:25:45 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-366165-2</guid>
        <source url="https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165.rss">[Discussion]Loading more new model</source>
      </item>
      <item>
        <title>[Discussion]Loading more new model</title>
        <dc:creator><![CDATA[@the_elve_age the elve age]]></dc:creator>
        <description><![CDATA[
          <p><a href="https://forum.moparisthebest.com/u/the_elve_age">@the_elve_age</a> wrote:</p>
          <blockquote>
              <p>So… From the last time I decided to peak into the 317 client.</p>
<p>Everyone is overwriting models, to add new ones.</p>
<p>From what I understood, we couldn’t raise the newer model limit…</p>
<p>So why? And if not, explain. (This isn’t a help section)</p>
          </blockquote>
          <p><a href="https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165/1">Read full topic</a></p>
        ]]></description>
        <link>https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165/1</link>
        <pubDate>Wed, 27 Oct 2010 01:19:22 +0000</pubDate>
        <guid isPermaLink="false">forum.moparisthebest.com-post-366165-1</guid>
        <source url="https://forum.moparisthebest.com/t/discussion-loading-more-new-model/366165.rss">[Discussion]Loading more new model</source>
      </item>
  </channel>
</rss>
